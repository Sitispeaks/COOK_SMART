{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# Recognize ingredients using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBMcobPHdD8O"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# from google_images_download import google_images_download\n",
    "\n",
    "try:\n",
    "  # The %tensorflow_version magic only works in colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOG3l_MsBO1A"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNnr21w1Y12Z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense,AveragePooling2D,BatchNormalization,Conv2D,Input,Flatten,Activation,concatenate,Dropout,GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "## Setup Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLPn-oPUFxKj"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pinKbdR0SY1i"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ta-fKS_NFyAQ"
   },
   "outputs": [],
   "source": [
    "path = 'drive/My Drive/Project ideas/Recipe_Finder/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2Z6nImiY0P6"
   },
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9jN9iNpd34W"
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join('/content/drive/My Drive/Project ideas/Recipe_Finder/', 'downloads') #'drive/My Drive/Project ideas/Recipe_Finder/downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZ_pxADxjPhu"
   },
   "outputs": [],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYudogtPjuM-"
   },
   "outputs": [],
   "source": [
    "os.chdir(base_dir)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sshtKY9V36Hi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nV8ZF5DooNet"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2nMbeFDoNbq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2PBzOf13v-H"
   },
   "source": [
    "# Method-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQl3ps0CZGWX"
   },
   "source": [
    "## Train and test Image set preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4gTv7ig2vMh"
   },
   "source": [
    "Use `ImageDataGenerator` to rescale the images.\n",
    "\n",
    "Create the train generator and specify where the train dataset directory, image size, batch size.\n",
    "\n",
    "Create the validation generator with similar approach as the train generator with the flow_from_directory() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCLb_yV5JfF3"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2)\n",
    "\n",
    "# rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest',\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset='training')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7pKECp3NMJh"
   },
   "outputs": [],
   "source": [
    "datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6En_A-Uniiu"
   },
   "outputs": [],
   "source": [
    "# len_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cU6Oer3rniaN"
   },
   "outputs": [],
   "source": [
    "x,y = train_generator.next()\n",
    "for i in range(0,3):\n",
    "    image = x[i]\n",
    "    label = y[i]\n",
    "    print (label)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VV0czi52Ab4R"
   },
   "outputs": [],
   "source": [
    "sbase_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tx1L7fxxWA_G"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrFFcwUb3iK9"
   },
   "source": [
    "Save the labels in a file which will be downloaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QFZIhWs4dsq"
   },
   "outputs": [],
   "source": [
    "print (train_generator.class_indices)\n",
    "\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzQjQs8z9c8E"
   },
   "outputs": [],
   "source": [
    "print(len(train_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duxD_UDSOmng"
   },
   "outputs": [],
   "source": [
    "!cat labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7sOyMqH1Hlj"
   },
   "outputs": [],
   "source": [
    "input_shape_img = (image_batch.shape[1],image_batch.shape[2],image_batch.shape[3])\n",
    "print(input_shape_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkH-kazQecHB"
   },
   "source": [
    "## Create the base model from the pre-trained convnets\n",
    "\n",
    "Create the base model from the **MobileNet V2** model developed at Google, and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.\n",
    "\n",
    "First, pick which intermediate layer of MobileNet V2 will be used for feature extraction. A common practice is to use the output of the very last layer before the flatten operation, the so-called \"bottleneck layer\". The reasoning here is that the following fully-connected layers will be too specialized to the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
    "\n",
    "Let's instantiate an MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top, which is ideal for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19IQ2gqneqmS"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndcjUhwNO10A"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine tune from this layer onwards\n",
    "fine_tune_at = 100 #20 # 100 thila\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYOs3A2M705l"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OPvAekr8BqA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QztX0g4fvpTI"
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2,l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbGXpPm7jzv9"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation= 'relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "#   tf.keras.layers.Conv2D(filters = 512, kernel_size = (3,3), activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(150, activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaTvNoSCrWSo"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmIm1rNY9qCR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# sgd = tf.keras.optimizers.SGD(lr = 0.1,momentum = 0.7, nesterov = True)\n",
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "adam_0 = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rmsprop, #adam_0,#adam #rmsprop  \n",
    "              metrics=['accuracy'])\n",
    "# print('Compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mq68Sei87oA3"
   },
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "\n",
    "# Call Backs\n",
    "filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "history = tf.keras.callbacks.History()\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "filepath = \"weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "path = os.path.abspath('__model_save/')\n",
    "\n",
    "filepath = os.path.join(path, filepath)\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=10, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint_save = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stoping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25)\n",
    "callbacks_list = [checkpoint_save,history,tensorboard,learning_rate_reduction,early_stoping]#learning_rate_reduction,early_stoping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-gjzo8D0eMv"
   },
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVuq2kZp0Wsi"
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpLzjW607n-Q"
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "\n",
    "model.load_weights(os.path.join(path, 'weights.28-0.65.hdf5')) # weights.52-1.54  # 40-1.67.hdf5 # weights.01-1.53\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=epochs, callbacks = callbacks_list, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TCZRQCV7n6n"
   },
   "outputs": [],
   "source": [
    "  #Loss plot\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1.2])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,3.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nb582E-7c4ZX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRDabW_u1wnv"
   },
   "source": [
    "## Convert to TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNvMl6CM6lG4"
   },
   "source": [
    "Saved the model using `tf.saved_model.save` and then convert the saved model to a tf lite compatible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LZiKVInWNGy"
   },
   "outputs": [],
   "source": [
    "saved_model_dir = 'save/fine_tuning'\n",
    "tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GE4w-9S410Dk"
   },
   "source": [
    "Download the converted model and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x47uW_lI1DoV"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('model.tflite')\n",
    "files.download('labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfXEmsxQf6eP"
   },
   "source": [
    "Let's take a look at the learning curves of the training and validation accuracy/loss, when fine tuning the last few layers of the MobileNet V2 base model and training the classifier on top of it. The validation loss is much higher than the training loss, so you may get some overfitting.\n",
    "\n",
    "You may also get some overfitting as the new training set is relatively small and similar to the original MobileNet V2 datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chW103JUItdk"
   },
   "outputs": [],
   "source": [
    "acc = history_fine.history['accuracy']\n",
    "val_acc = history_fine.history['val_accuracy']\n",
    "\n",
    "loss = history_fine.history['loss']\n",
    "val_loss = history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KI5FcX24c4oG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkYkme8bc5NQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9t5D1-Wc5LS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr0f6Utfc5Gm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2x9mDA_EgrC"
   },
   "source": [
    "## CNN 4 layer Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Bj_rOKPc5Dy"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, input_shape=input_shape_img, activation='relu', padding='same', ),\n",
    "  tf.keras.layers.MaxPooling2D(2),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "  tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation= 'relu', padding='same', kernel_initializer = 'he_uniform'),\n",
    "  tf.keras.layers.MaxPooling2D(2),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "  tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation= 'relu', padding='same', kernel_initializer = 'he_uniform'),\n",
    "  tf.keras.layers.MaxPooling2D(2),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "  tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation= 'relu', padding='same', kernel_initializer = 'he_uniform'),\n",
    "  tf.keras.layers.MaxPooling2D(2),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BuLPc4NR5r8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "history = tf.keras.callbacks.History()\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "filepath = \"own_weights-epoch:{epoch:02d}-train_acc{accuracy:.2f}-test_acc{val_accuracy:.2f}.hdf5\"\n",
    "path = os.path.abspath('__model_save/')\n",
    "filepath = os.path.join(path, filepath)\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint_save = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stoping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25)\n",
    "callbacks_list = [checkpoint_save,history,tensorboard,learning_rate_reduction,early_stoping]#learning_rate_reduction,early_stoping]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4VIe8Icc4_y"
   },
   "outputs": [],
   "source": [
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "adam_0 = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print('Compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bg2Qojnqc49B"
   },
   "outputs": [],
   "source": [
    "\n",
    "# own_weights.23-2.37.hdf5\n",
    "# model.load_weights(os.path.join(path, 'own_weights.27-2.29.hdf5'))\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=100, callbacks = callbacks_list, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWdTo9iuc45T"
   },
   "outputs": [],
   "source": [
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "adam_0 = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print('Compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NkyU81831DF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BxRhq4eSaa5a"
   },
   "source": [
    "## Inception Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQK3n0ADbix7"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "insp_base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4oUfiSuzqnM"
   },
   "outputs": [],
   "source": [
    "\n",
    "for layer in insp_base_model.layers[:20]: # add [:50] for next time\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HlN4ahCaZ-g"
   },
   "outputs": [],
   "source": [
    "\n",
    "insp_model = tf.keras.Sequential([\n",
    "  insp_base_model,\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(name='avg_pool'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])        \n",
    "\n",
    "insp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqRVrTQOa98V"
   },
   "outputs": [],
   "source": [
    "history = tf.keras.callbacks.History()\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "filepath = \"insp_weights-epoch:{epoch:02d}-train_acc:_{accuracy:.2f}-test_acc:_{val_accuracy:.2f}.hdf5\"\n",
    "path = os.path.abspath('__model_save/')\n",
    "filepath = os.path.join(path, filepath)\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint_save = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stoping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25)\n",
    "callbacks_list = [checkpoint_save,history,tensorboard,learning_rate_reduction,early_stoping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKPaYg-fb0a-"
   },
   "outputs": [],
   "source": [
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "adam_0 = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "insp_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print('Compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqO4pxoza953"
   },
   "outputs": [],
   "source": [
    "\n",
    "# own_weights.23-2.37.hdf5\n",
    "# model.load_weights(os.path.join(path, 'own_weights.27-2.29.hdf5'))\n",
    "\n",
    "history = insp_model.fit_generator(train_generator, epochs=100, callbacks = callbacks_list, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O44Dw8VyUcAt"
   },
   "source": [
    "## VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jd2_HX2Bbyrq"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "vgg16_base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjFxpECmUmiI"
   },
   "outputs": [],
   "source": [
    "\n",
    "for layer in vgg16_base_model.layers[:]: # add [:50] for next time\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ylzW7RVUmft"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vgg16_model = tf.keras.Sequential([\n",
    "  vgg16_base_model,\n",
    "  tf.keras.layers.Conv2D(filters = 128, kernel_size = 2, activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Conv2D(filters = 256, kernel_size = 2, activation= 'relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "#   tf.keras.layers.Conv2D(filters = 512, kernel_size = (3,3), activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(150, activation= 'relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_IMj3pyUmcR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "history = tf.keras.callbacks.History()\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "filepath = \"vgg_weights-epoch:{epoch:02d}-train_acc:_{accuracy:.2f}-test_acc:_{val_accuracy:.2f}.hdf5\"\n",
    "path = os.path.abspath('__model_save/')\n",
    "filepath = os.path.join(path, filepath)\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint_save = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stoping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25)\n",
    "callbacks_list = [checkpoint_save,history,tensorboard,learning_rate_reduction,early_stoping]#learning_rate_reduction,early_stoping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCM99SNzUmYm"
   },
   "outputs": [],
   "source": [
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "adam_0 = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "vgg16_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print('Compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQkfeoUhUyuM"
   },
   "outputs": [],
   "source": [
    "                                            #vgg_weights-epoch_31-train_acc__0.99-test_acc__0.75\n",
    "vgg16_model.load_weights(os.path.join(path, 'vgg_weights-epoch_31-train_acc__0.99-test_acc__0.75.hdf5'))#'vgg_weights-epoch:31-train_acc:_0.99-test_acc:_0.75.hdf5'))\n",
    "\n",
    "history = vgg16_model.fit_generator(train_generator, epochs=100, callbacks = callbacks_list, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNILmEVpUynT"
   },
   "outputs": [],
   "source": [
    "  #Loss plot\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1.2])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,3.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZH30mlOJshl"
   },
   "source": [
    "### Saving to tflite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQH0I70LJsPQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8vH4rCcUykY"
   },
   "outputs": [],
   "source": [
    "saved_model_dir = 'save/fine_tuning'\n",
    "tf.saved_model.save(vgg16_model, saved_model_dir)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model_75.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1bwbfiDJyf7"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('model_75.tflite')\n",
    "files.download('labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84pLMXrJSwJV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "00tXev_3hL75",
    "MWwMNqJcq1X6"
   ],
   "name": "cook_smart_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
